{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DiabtetesPredictions.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakesidetech/Altitude-and-Mortality-csv-file-lmdata/blob/main/DiabtetesPredictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY_EhByYIV1M"
      },
      "source": [
        "#import pandas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# import the metrics class\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# load dataset\n",
        "df = pd.read_csv(\"/content/diabetes.csv\", sep=',', na_values=\".\")\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQsFjnomUl89"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvAgl9RNJbfv"
      },
      "source": [
        "# target and features\n",
        "y = df.Outcome \n",
        "x = df.drop(columns=['Outcome'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42d1CMeNKhP9"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54sARybCKmzb"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrXYEbGWK1Rk"
      },
      "source": [
        "#4: Split into training and test set \n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGzFp-4eVOfm"
      },
      "source": [
        "#5: Create and fit your model using KNeighbors classification for five neighbors (sklearn)\n",
        "# KNN model fit\n",
        "knn = KNeighborsClassifier(n_neighbors=5) \n",
        "knn.fit(x_train, y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh18JlOpVeQ9"
      },
      "source": [
        " # Predict on dataset which model has not seen before \n",
        "predictions = knn.predict(x_test)\n",
        "#predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkppun7kLVuO"
      },
      "source": [
        "#6: Calculate the model accuracy of the model accuracy\n",
        "accuracy_score = metrics.accuracy_score(y_test, predictions)\n",
        "print('Accuracy Score = ', round(accuracy_score,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O78YQAGLi_Y"
      },
      "source": [
        "confusion_matrix = pd.crosstab(y_test, predictions,rownames=['Actual'], colnames=['Predicted'])\n",
        "print (confusion_matrix)\n",
        "TN = confusion_matrix.iloc[0,0]\n",
        "FN = confusion_matrix.iloc[0,1]\n",
        "TP = confusion_matrix.iloc[1,1]\n",
        "FP = confusion_matrix.iloc[1,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PeQujoVWEpB"
      },
      "source": [
        "#8: Print the TN, FN, TP, FP values\n",
        "print('True Negative =',TN)\n",
        "print('False Negative =',FN)\n",
        "print('True Positive =',TP)\n",
        "print('False Positive =',FP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQZtcXbbMC80"
      },
      "source": [
        "# 9: Print the model precision value\n",
        "# Precision is the ratio of  tp / (tp + fp)\n",
        "myprecision = TP / (TP + FP)\n",
        "print('Precision = ', round(myprecision,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYAkJkHaMNg_"
      },
      "source": [
        "#10: # Recall = the ratio tp / (tp + fn) \n",
        "myrecall = TP / (TP + FN)\n",
        "print('Recall = ', round(myrecall,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4a5MVP3MpaY"
      },
      "source": [
        "#11: Visualize the confusion matrix with a Heatmap \n",
        "ax = plt.axes()\n",
        "ax.set_title('Confusion Matrix with Heatmap')\n",
        "sns.heatmap(confusion_matrix, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPNUzXUPW_1b"
      },
      "source": [
        "#This is a list of rates that are often computed from a \n",
        "#confusion matrix for a binary classifier:\n",
        "\n",
        "#Accuracy: Overall, how often is the classifier correct?\n",
        "#(TP+TN)/total = (100+50)/165 = 0.91\n",
        "#Misclassification Rate: Overall, how often is it wrong?\n",
        "#(FP+FN)/total = (10+5)/165 = 0.09\n",
        "#equivalent to 1 minus Accuracy\n",
        "#also known as \"Error Rate\"\n",
        "#True Positive Rate: When it's actually yes, how often does it predict yes?\n",
        "#TP/actual yes = 100/105 = 0.95\n",
        "#also known as \"Sensitivity\" or \"Recall\"\n",
        "#False Positive Rate: When it's actually no, how often does it predict yes?\n",
        "#FP/actual no = 10/60 = 0.17\n",
        "#True Negative Rate: When it's actually no, how often does it predict no?\n",
        "#TN/actual no = 50/60 = 0.83\n",
        "#equivalent to 1 minus False Positive Rate\n",
        "#also known as \"Specificity\"\n",
        "#Precision: When it predicts yes, how often is it correct?\n",
        "#TP/predicted yes = 100/110 = 0.91\n",
        "#Prevalence: How often does the yes condition actually occur in our sample?\n",
        "#actual yes/total = 105/165 = 0.64"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}